# ==============================================================================
# Full-Stack Demo - Production-like Docker Compose
# ==============================================================================
# This demonstrates a complete multi-service deployment with:
# - Frontend (Nginx serving static files)
# - API Server (Python/Flask)
# - PostgreSQL Database
# - Redis Cache
# - RabbitMQ Message Queue
# - Background Worker
# - Monitoring (Prometheus + Grafana)
# ==============================================================================

services:
    # ============================================================================
    # Frontend - Nginx serving static files
    # ============================================================================
    frontend:
        image: nginx:alpine
        ports:
            - "80:80"
        volumes:
            - ./static:/usr/share/nginx/html:ro
        depends_on:
            - api
        healthcheck:
            test: ["CMD", "wget", "-q", "-O", "-", "http://localhost/health"]
            interval: 10s
            timeout: 5s
            retries: 3
        restart: always
        networks:
            - frontend-net
            - backend-net

    # ============================================================================
    # API Server - Python Flask
    # ============================================================================
    api:
        build:
            context: .
            dockerfile: Dockerfile.api
        ports:
            - "8080:8080"
        environment:
            # Database
            - DATABASE_URL=${DATABASE_URL}
            - DB_POOL_SIZE=${DB_POOL_SIZE}
            - DB_MAX_OVERFLOW=${DB_MAX_OVERFLOW}
            # Redis
            - REDIS_URL=${REDIS_URL}
            - REDIS_PASSWORD=${REDIS_PASSWORD}
            # RabbitMQ
            - RABBITMQ_URL=${RABBITMQ_URL}
            - RABBITMQ_USER=${RABBITMQ_USER}
            - RABBITMQ_PASSWORD=${RABBITMQ_PASSWORD}
            # API Keys
            - JWT_SECRET=${JWT_SECRET}
            - API_KEY=${API_KEY}
            - ENCRYPTION_KEY=${ENCRYPTION_KEY}
            # External Services
            - STRIPE_SECRET_KEY=${STRIPE_SECRET_KEY}
            - STRIPE_WEBHOOK_SECRET=${STRIPE_WEBHOOK_SECRET}
            - SENDGRID_API_KEY=${SENDGRID_API_KEY}
            - TWILIO_ACCOUNT_SID=${TWILIO_ACCOUNT_SID}
            - TWILIO_AUTH_TOKEN=${TWILIO_AUTH_TOKEN}
            - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
            - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
            - S3_BUCKET=${S3_BUCKET}
            # OAuth
            - GOOGLE_CLIENT_ID=${GOOGLE_CLIENT_ID}
            - GOOGLE_CLIENT_SECRET=${GOOGLE_CLIENT_SECRET}
            - GITHUB_CLIENT_ID=${GITHUB_CLIENT_ID}
            - GITHUB_CLIENT_SECRET=${GITHUB_CLIENT_SECRET}
            # Monitoring
            - SENTRY_DSN=${SENTRY_DSN}
            - DATADOG_API_KEY=${DATADOG_API_KEY}
            # App Config
            - APP_ENV=${APP_ENV}
            - DEBUG=${DEBUG}
            - LOG_LEVEL=${LOG_LEVEL}
        depends_on:
            db:
                condition: service_healthy
            redis:
                condition: service_healthy
            rabbitmq:
                condition: service_healthy
        healthcheck:
            test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
            interval: 10s
            timeout: 5s
            retries: 5
        restart: always
        networks:
            - backend-net
        deploy:
            resources:
                limits:
                    cpus: "1"
                    memory: 512M

    # ============================================================================
    # Background Worker - Processes async jobs
    # ============================================================================
    worker:
        build:
            context: .
            dockerfile: Dockerfile.worker
        environment:
            - DATABASE_URL=${DATABASE_URL}
            - REDIS_URL=${REDIS_URL}
            - REDIS_PASSWORD=${REDIS_PASSWORD}
            - RABBITMQ_URL=${RABBITMQ_URL}
            - RABBITMQ_USER=${RABBITMQ_USER}
            - RABBITMQ_PASSWORD=${RABBITMQ_PASSWORD}
            - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
            - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
            - SENDGRID_API_KEY=${SENDGRID_API_KEY}
            - SENTRY_DSN=${SENTRY_DSN}
        depends_on:
            - db
            - redis
            - rabbitmq
        restart: always
        networks:
            - backend-net
        deploy:
            replicas: 2
            resources:
                limits:
                    cpus: "0.5"
                    memory: 256M

    # ============================================================================
    # PostgreSQL Database
    # ============================================================================
    db:
        image: postgres:15-alpine
        environment:
            - POSTGRES_USER=${POSTGRES_USER}
            - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
            - POSTGRES_DB=${POSTGRES_DB}
        volumes:
            - postgres_data:/var/lib/postgresql/data
            - ./init.sql:/docker-entrypoint-initdb.d/init.sql:ro
        healthcheck:
            test:
                [
                    "CMD-SHELL",
                    "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}",
                ]
            interval: 15s
            timeout: 10s
            retries: 10
        restart: always
        networks:
            - backend-net
        deploy:
            resources:
                limits:
                    cpus: "1"
                    memory: 1G

    # ============================================================================
    # Redis Cache
    # ============================================================================
    redis:
        image: redis:7-alpine
        command: redis-server --requirepass ${REDIS_PASSWORD} --appendonly yes
        volumes:
            - redis_data:/data
        healthcheck:
            test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
            interval: 5s
            timeout: 3s
            retries: 5
        restart: always
        networks:
            - backend-net

    # ============================================================================
    # RabbitMQ Message Queue
    # ============================================================================
    rabbitmq:
        image: rabbitmq:3-management-alpine
        environment:
            - RABBITMQ_DEFAULT_USER=${RABBITMQ_USER}
            - RABBITMQ_DEFAULT_PASS=${RABBITMQ_PASSWORD}
        ports:
            - "15672:15672" # Management UI
        volumes:
            - rabbitmq_data:/var/lib/rabbitmq
        healthcheck:
            test: ["CMD", "rabbitmq-diagnostics", "-q", "ping"]
            interval: 30s
            timeout: 20s
            retries: 10
        restart: always
        networks:
            - backend-net

    # ============================================================================
    # Prometheus - Metrics Collection
    # ============================================================================
    prometheus:
        image: prom/prometheus:latest
        ports:
            - "9090:9090"
        volumes:
            - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
            - prometheus_data:/prometheus
        command:
            - "--config.file=/etc/prometheus/prometheus.yml"
            - "--storage.tsdb.path=/prometheus"
        restart: always
        networks:
            - monitoring-net
            - backend-net

    # ============================================================================
    # Grafana - Dashboard
    # ============================================================================
    grafana:
        image: grafana/grafana:latest
        ports:
            - "3000:3000"
        environment:
            - GF_SECURITY_ADMIN_USER=${GRAFANA_USER}
            - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
            - GF_INSTALL_PLUGINS=grafana-clock-panel
        volumes:
            - grafana_data:/var/lib/grafana
        depends_on:
            - prometheus
        restart: always
        networks:
            - monitoring-net

# ==============================================================================
# Networks
# ==============================================================================
networks:
    frontend-net:
        driver: bridge
    backend-net:
        driver: bridge
    monitoring-net:
        driver: bridge

# ==============================================================================
# Volumes
# ==============================================================================
volumes:
    postgres_data:
    redis_data:
    rabbitmq_data:
    prometheus_data:
    grafana_data:
